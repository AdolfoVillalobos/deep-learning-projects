{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word 2 Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset Generator\n",
    "\n",
    "\n",
    "We start by creating a sampling table. This object will help us choose negative examples from the most common words in the vocabulary such as \"the\", \"is\", \"on\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Generate Training Data.\n",
    "\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "    \n",
    "    targets, contexts, labels = [], [] , []\n",
    "    \n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=vocab_size)\n",
    "    \n",
    "    for sequence in tqdm.tqdm(sequences):\n",
    "        \n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          sequence, \n",
    "          vocabulary_size=vocab_size,\n",
    "          sampling_table=sampling_table,\n",
    "          window_size=window_size,\n",
    "          negative_samples=0)\n",
    "        \n",
    "        for target_word, context_word in positive_skip_grams:\n",
    "            \n",
    "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "            \n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                                                                  true_classes=context_class,\n",
    "                                                                  num_true=1, \n",
    "                                                                  num_sampled=num_ns, \n",
    "                                                                  unique=True, \n",
    "                                                                  range_max=vocab_size, \n",
    "                                                                  seed=SEED, \n",
    "                                                                  name=\"negative_sampling\")\n",
    "            \n",
    "            negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
    "            context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "            label = tf.constant([1]+[0]*num_ns, dtype=\"int64\")\n",
    "            \n",
    "            targets.append(target_word)\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "            \n",
    "    \n",
    "    return targets, contexts, labels\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1122304/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as f: \n",
    "    lines = f.read().splitlines()\n",
    "    print(len(lines))\n",
    "for line in lines[:20]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Remove empty lines and create and object wo which tf can operate.\n",
    "2. Remove punctuation.\n",
    "3. Lower case.\n",
    "4. Vectorize sentences. \n",
    "5. Save Created Vocabulary for reference\n",
    "6. Generate vectors for each element in corpus\n",
    "7. Generate training examples from vector sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the TextLineDataset function from Tensorflow.\n",
    "\n",
    "# We load only non-empty lines\n",
    "\n",
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a custom standardization function to lowercase the text and  remove punctuation.\n",
    "\n",
    "# This is implemented with the TextVectorization object\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "# Define the vocabulary size and number of words in a sequence.\n",
    "\n",
    "vocab_size = 4096\n",
    "sequence_length = 10\n",
    "\n",
    "# Use the text vectorization layer to normalize, split, and map strings to\n",
    "# integers. Set output_sequence_length length to pad all samples to same length.\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds.batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in', 'is', 'not', 'for', 'with', 'me', 'it', 'be', 'your']\n"
     ]
    }
   ],
   "source": [
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return tf.squeeze(vectorize_layer(text))\n",
    "\n",
    "# Vectorize the data in text_ds.\n",
    "\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_text).unbatch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_UnbatchDataset shapes: <unknown>, types: tf.int64>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32777\n",
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n",
      "[138  36 982 144 673 125  16 106   0   0] => ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n",
      "[34  0  0  0  0  0  0  0  0  0] => ['all', '', '', '', '', '', '', '', '', '']\n",
      "[106 106   0   0   0   0   0   0   0   0] => ['speak', 'speak', '', '', '', '', '', '', '', '']\n",
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))\n",
    "\n",
    "for seq in sequences[:5]:\n",
    "    print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32777/32777 [00:06<00:00, 5336.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.87 s, sys: 179 ms, total: 6.05 s\n",
      "Wall time: 6.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "targets, contexts, labels = generate_training_data(sequences=sequences,\n",
    "                                                  window_size=2,\n",
    "                                                  num_ns=4,\n",
    "                                                  vocab_size=vocab_size,\n",
    "                                                  seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65812 65812 65812\n"
     ]
    }
   ],
   "source": [
    "print(len(targets), len(contexts), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Dataset For Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (((1024,), (1024, 5, 1)), (1024, 5)), types: ((tf.int32, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: (((1024,), (1024, 5, 1)), (1024, 5)), types: ((tf.int32, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model And Training\n",
    "\n",
    "The Word2Vec model can be implemented as a classifier to distinguish between true context words from skipgrams and false context words obtained through negatve sampling.\n",
    "\n",
    "This can be done by calculating a dot product between the embeddings of target and contextwords. This allows us to obtain predictions for labels and compute the loss against the true labels.\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "We will use the following layers from Keras.\n",
    "1. target embedding: Looks up he embedding of a word when appears as a target word.\n",
    "2. context embedding: Looks up the embedding of a word when appears as a context word.\n",
    "3. dots: keras.Dots. Computs the dot product between the embedding vectors of the target and context words.\n",
    "4. flatten: Flattens the results of the dot product into logits.\n",
    "\n",
    "Similar to pytorch's forward method, we will use the <code> call() </code> method to accept (target, context) pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(Model):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, num_ns):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.target_embedding = Embedding(vocab_size, embedding_dim, input_length=1, name=\"w2v_embedding\")\n",
    "        self.context_embedding = Embedding(vocab_size, embedding_dim, input_length=num_ns+1)\n",
    "        \n",
    "        self.dots = Dot(axes=(3,2))\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "    def call(self, pair):\n",
    "        \n",
    "        target, context = pair\n",
    "        we = self.target_embedding(target)\n",
    "        ce = self.context_embedding(context)\n",
    "        \n",
    "        \n",
    "        dots = self.dots([ce, we])\n",
    "        \n",
    "        return self.flatten(dots)\n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(x_logit, y_true):\n",
    "    return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size=vocab_size, embedding_dim=embedding_dim, num_ns=4)\n",
    "word2vec.compile(optimizer=\"adam\", loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.9025\n",
      "Epoch 2/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.9089\n",
      "Epoch 3/50\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.9151\n",
      "Epoch 4/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.9207\n",
      "Epoch 5/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.9254\n",
      "Epoch 6/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.9301\n",
      "Epoch 7/50\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.3208 - accuracy: 0.9340\n",
      "Epoch 8/50\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.3062 - accuracy: 0.9369\n",
      "Epoch 9/50\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.2928 - accuracy: 0.9401\n",
      "Epoch 10/50\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.2804 - accuracy: 0.9424\n",
      "Epoch 11/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2690 - accuracy: 0.9446\n",
      "Epoch 12/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2585 - accuracy: 0.9467\n",
      "Epoch 13/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.9482\n",
      "Epoch 14/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2397 - accuracy: 0.9501\n",
      "Epoch 15/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.9518\n",
      "Epoch 16/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2234 - accuracy: 0.9528\n",
      "Epoch 17/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2162 - accuracy: 0.9540\n",
      "Epoch 18/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2094 - accuracy: 0.9548\n",
      "Epoch 19/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2031 - accuracy: 0.9558\n",
      "Epoch 20/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1972 - accuracy: 0.9566\n",
      "Epoch 21/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1917 - accuracy: 0.9573\n",
      "Epoch 22/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1865 - accuracy: 0.9578\n",
      "Epoch 23/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1816 - accuracy: 0.9586\n",
      "Epoch 24/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1771 - accuracy: 0.9589\n",
      "Epoch 25/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1728 - accuracy: 0.9594\n",
      "Epoch 26/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1688 - accuracy: 0.9598\n",
      "Epoch 27/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1650 - accuracy: 0.9602\n",
      "Epoch 28/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1614 - accuracy: 0.9606\n",
      "Epoch 29/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1581 - accuracy: 0.9610\n",
      "Epoch 30/50\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.1549 - accuracy: 0.9613\n",
      "Epoch 31/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.9615\n",
      "Epoch 32/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9617\n",
      "Epoch 33/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1463 - accuracy: 0.9619\n",
      "Epoch 34/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9620\n",
      "Epoch 35/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9621\n",
      "Epoch 36/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1391 - accuracy: 0.9622\n",
      "Epoch 37/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1369 - accuracy: 0.9622\n",
      "Epoch 38/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1348 - accuracy: 0.9624\n",
      "Epoch 39/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9625\n",
      "Epoch 40/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9626\n",
      "Epoch 41/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9628\n",
      "Epoch 42/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.9630\n",
      "Epoch 43/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9631\n",
      "Epoch 44/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9633\n",
      "Epoch 45/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1229 - accuracy: 0.9634\n",
      "Epoch 46/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1215 - accuracy: 0.9634\n",
      "Epoch 47/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9635\n",
      "Epoch 48/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1188 - accuracy: 0.9635\n",
      "Epoch 49/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9634\n",
      "Epoch 50/50\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1164 - accuracy: 0.9634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fef988f4c70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=50, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 98832), started 0:00:55 ago. (Use '!kill 98832' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-724741ce04dfb60e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-724741ce04dfb60e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
