{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Original"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n    -O /tmp/cats_and_dogs_filtered.zip","execution_count":1,"outputs":[{"output_type":"stream","text":"--2020-11-21 21:31:50--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 172.253.123.128, 173.194.217.128, 74.125.31.128, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|172.253.123.128|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 68606236 (65M) [application/zip]\nSaving to: ‘/tmp/cats_and_dogs_filtered.zip’\n\n/tmp/cats_and_dogs_ 100%[===================>]  65.43M  89.7MB/s    in 0.7s    \n\n2020-11-21 21:31:51 (89.7 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport zipfile\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nlocal_zip = '/tmp/cats_and_dogs_filtered.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('/tmp')\nzip_ref.close()\n\nbase_dir = '/tmp/cats_and_dogs_filtered'\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'validation')\n\n# Directory with our training cat pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\n\n# Directory with our training dog pictures\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\n\n# Directory with our validation cat pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\n\n# Directory with our validation dog pictures\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=RMSprop(lr=1e-4),\n              metrics=['accuracy'])\n\n# All images will be rescaled by 1./255\ntrain_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(150, 150),  # All images will be resized to 150x150\n        batch_size=20,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='binary')\n\nhistory = model.fit(\n      train_generator,\n      steps_per_epoch=100,  # 2000 images = batch_size * steps\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=50,  # 1000 images = batch_size * steps\n      verbose=2)\n","execution_count":null,"outputs":[{"output_type":"stream","text":"Found 2000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\nEpoch 1/100\n100/100 - 8s - loss: 0.6900 - accuracy: 0.5380 - val_loss: 0.6678 - val_accuracy: 0.6010\nEpoch 2/100\n100/100 - 8s - loss: 0.6569 - accuracy: 0.6005 - val_loss: 0.6498 - val_accuracy: 0.6260\nEpoch 3/100\n100/100 - 9s - loss: 0.6076 - accuracy: 0.6800 - val_loss: 0.6123 - val_accuracy: 0.6620\nEpoch 4/100\n100/100 - 9s - loss: 0.5708 - accuracy: 0.7180 - val_loss: 0.6046 - val_accuracy: 0.6590\nEpoch 5/100\n100/100 - 8s - loss: 0.5367 - accuracy: 0.7300 - val_loss: 0.6594 - val_accuracy: 0.6050\nEpoch 6/100\n100/100 - 8s - loss: 0.5035 - accuracy: 0.7500 - val_loss: 0.5463 - val_accuracy: 0.7240\nEpoch 7/100\n100/100 - 9s - loss: 0.4781 - accuracy: 0.7745 - val_loss: 0.5414 - val_accuracy: 0.7310\nEpoch 8/100\n100/100 - 8s - loss: 0.4501 - accuracy: 0.7915 - val_loss: 0.5813 - val_accuracy: 0.7130\nEpoch 9/100\n100/100 - 8s - loss: 0.4237 - accuracy: 0.7970 - val_loss: 0.5506 - val_accuracy: 0.7270\nEpoch 10/100\n100/100 - 8s - loss: 0.4012 - accuracy: 0.8205 - val_loss: 0.6199 - val_accuracy: 0.6930\nEpoch 11/100\n100/100 - 9s - loss: 0.3709 - accuracy: 0.8380 - val_loss: 0.6880 - val_accuracy: 0.6840\nEpoch 12/100\n100/100 - 9s - loss: 0.3485 - accuracy: 0.8390 - val_loss: 0.5428 - val_accuracy: 0.7370\nEpoch 13/100\n100/100 - 8s - loss: 0.3221 - accuracy: 0.8640 - val_loss: 0.5525 - val_accuracy: 0.7460\nEpoch 14/100\n100/100 - 8s - loss: 0.3068 - accuracy: 0.8615 - val_loss: 0.5288 - val_accuracy: 0.7490\nEpoch 15/100\n100/100 - 8s - loss: 0.2803 - accuracy: 0.8860 - val_loss: 0.5764 - val_accuracy: 0.7400\nEpoch 16/100\n100/100 - 8s - loss: 0.2510 - accuracy: 0.8980 - val_loss: 0.5644 - val_accuracy: 0.7410\nEpoch 17/100\n100/100 - 8s - loss: 0.2357 - accuracy: 0.9010 - val_loss: 0.5573 - val_accuracy: 0.7490\nEpoch 18/100\n100/100 - 9s - loss: 0.2097 - accuracy: 0.9205 - val_loss: 0.5698 - val_accuracy: 0.7570\nEpoch 19/100\n100/100 - 8s - loss: 0.1856 - accuracy: 0.9385 - val_loss: 0.7554 - val_accuracy: 0.7100\nEpoch 20/100\n100/100 - 8s - loss: 0.1697 - accuracy: 0.9360 - val_loss: 0.5972 - val_accuracy: 0.7500\nEpoch 21/100\n100/100 - 8s - loss: 0.1454 - accuracy: 0.9540 - val_loss: 0.6753 - val_accuracy: 0.7310\nEpoch 22/100\n100/100 - 8s - loss: 0.1391 - accuracy: 0.9550 - val_loss: 0.6292 - val_accuracy: 0.7560\nEpoch 23/100\n100/100 - 8s - loss: 0.1169 - accuracy: 0.9595 - val_loss: 0.6660 - val_accuracy: 0.7470\nEpoch 24/100\n100/100 - 8s - loss: 0.1109 - accuracy: 0.9635 - val_loss: 0.7414 - val_accuracy: 0.7360\nEpoch 25/100\n100/100 - 8s - loss: 0.0908 - accuracy: 0.9745 - val_loss: 0.7863 - val_accuracy: 0.7310\nEpoch 26/100\n100/100 - 9s - loss: 0.0760 - accuracy: 0.9800 - val_loss: 0.7402 - val_accuracy: 0.7530\nEpoch 27/100\n100/100 - 8s - loss: 0.0657 - accuracy: 0.9820 - val_loss: 0.8646 - val_accuracy: 0.7280\nEpoch 28/100\n100/100 - 8s - loss: 0.0600 - accuracy: 0.9820 - val_loss: 0.8155 - val_accuracy: 0.7530\nEpoch 29/100\n100/100 - 8s - loss: 0.0432 - accuracy: 0.9905 - val_loss: 0.8873 - val_accuracy: 0.7400\nEpoch 30/100\n100/100 - 8s - loss: 0.0387 - accuracy: 0.9910 - val_loss: 1.1582 - val_accuracy: 0.7190\nEpoch 31/100\n100/100 - 8s - loss: 0.0395 - accuracy: 0.9905 - val_loss: 0.8998 - val_accuracy: 0.7650\nEpoch 32/100\n100/100 - 8s - loss: 0.0266 - accuracy: 0.9940 - val_loss: 0.9626 - val_accuracy: 0.7630\nEpoch 33/100\n100/100 - 9s - loss: 0.0313 - accuracy: 0.9920 - val_loss: 1.0140 - val_accuracy: 0.7440\nEpoch 34/100\n100/100 - 9s - loss: 0.0196 - accuracy: 0.9950 - val_loss: 1.0279 - val_accuracy: 0.7470\nEpoch 35/100\n100/100 - 8s - loss: 0.0156 - accuracy: 0.9975 - val_loss: 1.0395 - val_accuracy: 0.7510\nEpoch 36/100\n100/100 - 8s - loss: 0.0194 - accuracy: 0.9945 - val_loss: 1.1755 - val_accuracy: 0.7290\nEpoch 37/100\n100/100 - 8s - loss: 0.0206 - accuracy: 0.9950 - val_loss: 1.1502 - val_accuracy: 0.7550\nEpoch 38/100\n100/100 - 8s - loss: 0.0146 - accuracy: 0.9950 - val_loss: 1.1585 - val_accuracy: 0.7420\nEpoch 39/100\n100/100 - 8s - loss: 0.0137 - accuracy: 0.9970 - val_loss: 1.1438 - val_accuracy: 0.7430\nEpoch 40/100\n100/100 - 9s - loss: 0.0143 - accuracy: 0.9965 - val_loss: 1.2011 - val_accuracy: 0.7520\nEpoch 41/100\n100/100 - 8s - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.3847 - val_accuracy: 0.7360\nEpoch 42/100\n100/100 - 8s - loss: 0.0126 - accuracy: 0.9980 - val_loss: 1.2289 - val_accuracy: 0.7550\nEpoch 43/100\n100/100 - 8s - loss: 0.0157 - accuracy: 0.9960 - val_loss: 1.2696 - val_accuracy: 0.7540\nEpoch 44/100\n100/100 - 8s - loss: 0.0123 - accuracy: 0.9970 - val_loss: 1.3754 - val_accuracy: 0.7400\nEpoch 45/100\n100/100 - 8s - loss: 0.0126 - accuracy: 0.9965 - val_loss: 1.4172 - val_accuracy: 0.7430\nEpoch 46/100\n100/100 - 8s - loss: 0.0065 - accuracy: 0.9980 - val_loss: 2.8481 - val_accuracy: 0.6530\nEpoch 47/100\n100/100 - 8s - loss: 0.0132 - accuracy: 0.9970 - val_loss: 1.4027 - val_accuracy: 0.7500\nEpoch 48/100\n100/100 - 8s - loss: 0.0073 - accuracy: 0.9980 - val_loss: 1.3942 - val_accuracy: 0.7550\nEpoch 49/100\n100/100 - 8s - loss: 0.0107 - accuracy: 0.9965 - val_loss: 1.4694 - val_accuracy: 0.7410\nEpoch 50/100\n100/100 - 8s - loss: 0.0070 - accuracy: 0.9980 - val_loss: 1.4329 - val_accuracy: 0.7450\nEpoch 51/100\n100/100 - 8s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.4996 - val_accuracy: 0.7400\nEpoch 52/100\n100/100 - 8s - loss: 0.0072 - accuracy: 0.9975 - val_loss: 1.4665 - val_accuracy: 0.7420\nEpoch 53/100\n100/100 - 8s - loss: 0.0101 - accuracy: 0.9970 - val_loss: 1.5822 - val_accuracy: 0.7420\nEpoch 54/100\n100/100 - 8s - loss: 0.0028 - accuracy: 0.9995 - val_loss: 1.6130 - val_accuracy: 0.7460\nEpoch 55/100\n100/100 - 8s - loss: 0.0092 - accuracy: 0.9985 - val_loss: 1.6414 - val_accuracy: 0.7510\nEpoch 56/100\n100/100 - 8s - loss: 0.0094 - accuracy: 0.9970 - val_loss: 1.6764 - val_accuracy: 0.7410\nEpoch 57/100\n100/100 - 8s - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.5939 - val_accuracy: 0.7520\nEpoch 58/100\n100/100 - 8s - loss: 0.0072 - accuracy: 0.9975 - val_loss: 1.6574 - val_accuracy: 0.7370\nEpoch 59/100\n100/100 - 8s - loss: 0.0113 - accuracy: 0.9970 - val_loss: 1.6974 - val_accuracy: 0.7330\nEpoch 60/100\n100/100 - 8s - loss: 0.0115 - accuracy: 0.9965 - val_loss: 1.6594 - val_accuracy: 0.7400\nEpoch 61/100\n100/100 - 7s - loss: 0.0051 - accuracy: 0.9980 - val_loss: 1.7377 - val_accuracy: 0.7530\nEpoch 62/100\n100/100 - 9s - loss: 0.0073 - accuracy: 0.9985 - val_loss: 1.7108 - val_accuracy: 0.7470\nEpoch 63/100\n100/100 - 8s - loss: 0.0079 - accuracy: 0.9985 - val_loss: 1.8249 - val_accuracy: 0.7520\nEpoch 64/100\n100/100 - 8s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8645 - val_accuracy: 0.7450\nEpoch 65/100\n100/100 - 8s - loss: 9.1882e-04 - accuracy: 0.9995 - val_loss: 1.9125 - val_accuracy: 0.7490\nEpoch 66/100\n100/100 - 8s - loss: 0.0040 - accuracy: 0.9990 - val_loss: 1.9184 - val_accuracy: 0.7500\nEpoch 67/100\n100/100 - 8s - loss: 0.0044 - accuracy: 0.9980 - val_loss: 1.8898 - val_accuracy: 0.7580\nEpoch 68/100\n100/100 - 8s - loss: 0.0051 - accuracy: 0.9980 - val_loss: 1.8183 - val_accuracy: 0.7520\nEpoch 69/100\n100/100 - 8s - loss: 0.0073 - accuracy: 0.9985 - val_loss: 2.2125 - val_accuracy: 0.7110\nEpoch 70/100\n100/100 - 9s - loss: 0.0043 - accuracy: 0.9995 - val_loss: 1.8460 - val_accuracy: 0.7500\nEpoch 71/100\n100/100 - 8s - loss: 0.0034 - accuracy: 0.9985 - val_loss: 1.8875 - val_accuracy: 0.7480\nEpoch 72/100\n100/100 - 7s - loss: 1.5816e-04 - accuracy: 1.0000 - val_loss: 2.1049 - val_accuracy: 0.7370\nEpoch 73/100\n100/100 - 8s - loss: 0.0018 - accuracy: 0.9985 - val_loss: 1.8902 - val_accuracy: 0.7470\nEpoch 74/100\n100/100 - 8s - loss: 0.0089 - accuracy: 0.9980 - val_loss: 1.8630 - val_accuracy: 0.7480\nEpoch 75/100\n100/100 - 8s - loss: 0.0023 - accuracy: 0.9995 - val_loss: 1.9204 - val_accuracy: 0.7430\nEpoch 76/100\n100/100 - 7s - loss: 0.0101 - accuracy: 0.9965 - val_loss: 1.9407 - val_accuracy: 0.7610\nEpoch 77/100\n100/100 - 8s - loss: 3.5028e-05 - accuracy: 1.0000 - val_loss: 2.1307 - val_accuracy: 0.7390\nEpoch 78/100\n100/100 - 9s - loss: 0.0017 - accuracy: 0.9995 - val_loss: 3.6476 - val_accuracy: 0.6820\nEpoch 79/100\n100/100 - 8s - loss: 0.0122 - accuracy: 0.9970 - val_loss: 1.9775 - val_accuracy: 0.7420\nEpoch 80/100\n100/100 - 7s - loss: 0.0049 - accuracy: 0.9990 - val_loss: 2.2079 - val_accuracy: 0.7420\n","name":"stdout"},{"output_type":"stream","text":"Epoch 81/100\n100/100 - 8s - loss: 0.0023 - accuracy: 0.9995 - val_loss: 2.3181 - val_accuracy: 0.7440\nEpoch 82/100\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=RMSprop(lr=1e-4),\n              metrics=['accuracy'])\n\n# All images will be rescaled by 1./255\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode=\"nearest\")\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(150, 150),  # All images will be resized to 150x150\n        batch_size=20,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='binary')\n\nhistory = model.fit(\n      train_generator,\n      steps_per_epoch=100,  # 2000 images = batch_size * steps\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=50,  # 1000 images = batch_size * steps\n      verbose=2)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropout"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=RMSprop(lr=1e-4),\n              metrics=['accuracy'])\n\n# This code has changed. Now instead of the ImageGenerator just rescaling\n# the image, we also rotate and do other operations\n# Updated to do image augmentation\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(150, 150),  # All images will be resized to 150x150\n        batch_size=20,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='binary')\n\nhistory = model.fit(\n      train_generator,\n      steps_per_epoch=100,  # 2000 images = batch_size * steps\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=50,  # 1000 images = batch_size * steps\n      verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}